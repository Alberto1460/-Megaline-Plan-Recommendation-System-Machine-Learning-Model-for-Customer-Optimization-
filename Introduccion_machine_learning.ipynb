{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"text-align: center; font-size: 30px; color: red; font-family: 'Arial', sans-serif;\">\n",
    "    <b>Modelo de Machine Learning Megaline</b>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Contenido <a id='back'></a>\n",
    "\n",
    "* [Introducción](#intro)\n",
    "* [Etapa 1. Carga y Exploración de los Datos](#data_review)\n",
    "    * [1.1 Descripción de los Datos](#data_review)\n",
    "* [Etapa 2. Preparación de los Datos](#data_preparing)\n",
    "    * [2.1 División de los Datos en conjuntos de entrenamiento, validación y prueba](#data_divisions)\n",
    "* [Etapa 3. Desarrollo del Modelo](#data_model)\n",
    "    * [3.1 Selección del Modelo](#choose_model)\n",
    "    * [3.2 Entrenamiento del Modelo](#train_model)\n",
    "    * [3.3 Ajuste de Hiperparámetros](#hyperparametres)\n",
    "* [Etapa 4. Evaluación del Modelo](#model_evaluation)\n",
    "    * [4.1 Prueba de Cordura](#cordura_prueba)\n",
    "* [Conclusiones finales del proyecto](#end)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introducción<a id='intro'></a>\n",
    "En la actualidad, la personalización de servicios juega un papel fundamental en la fidelización de los clientes. Las compañías móviles, como Megaline, buscan constantemente optimizar la experiencia de sus usuarios mediante la oferta de planes más adecuados a sus necesidades. Sin embargo, muchos clientes aún mantienen planes heredados que pueden no ser los más beneficiosos para ellos. Para abordar este problema, Megaline ha decidido desarrollar un sistema que, basándose en el comportamiento de los usuarios, pueda recomendar uno de los nuevos planes disponibles: Smart o Ultra.\n",
    "\n",
    "Este proyecto tiene como objetivo construir un modelo de clasificación que analice el comportamiento mensual de los suscriptores de Megaline y sugiera el plan más adecuado para cada cliente. Utilizando datos históricos sobre las llamadas, mensajes, minutos y uso de internet, se pretende desarrollar un modelo de clasificación preciso que ayude a los clientes a tomar decisiones informadas sobre su plan móvil.\n",
    "\n",
    "Para este propósito, se emplearán técnicas de aprendizaje automático, dividiendo el conjunto de datos en subconjuntos de entrenamiento, validación y prueba, para evaluar diferentes algoritmos y ajustar los hiperparámetros de los modelos. El éxito del modelo estará determinado por su capacidad para alcanzar un umbral de precisión del 75%, y la prueba final del modelo incluirá una validación robusta para asegurar su fiabilidad en la toma de decisiones futuras."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Etapa 1. Carga y Exploración de los Datos <a id='data_review'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cargar librerias\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.dummy import DummyClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   calls  minutes  messages   mb_used  is_ultra\n",
      "0   40.0   311.90      83.0  19915.42         0\n",
      "1   85.0   516.75      56.0  22696.96         0\n",
      "2   77.0   467.66      86.0  21060.45         0\n",
      "3  106.0   745.53      81.0   8437.39         1\n",
      "4   66.0   418.74       1.0  14502.75         0\n",
      "\n",
      "Dimensiones del Dataset:  (3214, 5)\n",
      "\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 3214 entries, 0 to 3213\n",
      "Data columns (total 5 columns):\n",
      " #   Column    Non-Null Count  Dtype  \n",
      "---  ------    --------------  -----  \n",
      " 0   calls     3214 non-null   float64\n",
      " 1   minutes   3214 non-null   float64\n",
      " 2   messages  3214 non-null   float64\n",
      " 3   mb_used   3214 non-null   float64\n",
      " 4   is_ultra  3214 non-null   int64  \n",
      "dtypes: float64(4), int64(1)\n",
      "memory usage: 125.7 KB\n",
      "None\n",
      "\n",
      "             calls      minutes     messages       mb_used     is_ultra\n",
      "count  3214.000000  3214.000000  3214.000000   3214.000000  3214.000000\n",
      "mean     63.038892   438.208787    38.281269  17207.673836     0.306472\n",
      "std      33.236368   234.569872    36.148326   7570.968246     0.461100\n",
      "min       0.000000     0.000000     0.000000      0.000000     0.000000\n",
      "25%      40.000000   274.575000     9.000000  12491.902500     0.000000\n",
      "50%      62.000000   430.600000    30.000000  16943.235000     0.000000\n",
      "75%      82.000000   571.927500    57.000000  21424.700000     1.000000\n",
      "max     244.000000  1632.060000   224.000000  49745.730000     1.000000\n",
      "\n",
      "is_ultra\n",
      "0    2229\n",
      "1     985\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Importar el Modelo\n",
    "data = pd.read_csv('/home/josue/Introducción_al_machine_learning/users_behavior.csv')\n",
    "\n",
    "# Realizamos un head\n",
    "print(data.head())\n",
    "print()\n",
    "print('Dimensiones del Dataset: ', data.shape)\n",
    "print()\n",
    "print(data.info())\n",
    "print()\n",
    "print(data.describe())\n",
    "print()\n",
    "print(data['is_ultra'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como observamos en estos datos, se encuentran de forma correcta, no hay datos faltantes, esta la 'features' y 'target' para realizar el modelo, ahora procederemos a segmentar los datos. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Etapa 2. Preparación de los Datos <a id='data_preparing'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1 División de los Datos en conjuntos de entrenamiento, validación y prueba <a id='data_divisions'></a> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Conjunto de Entranamiento: (1928, 4), (1928,)\n",
      "Conjunto de Validación: (643, 4), (643,)\n",
      "Conjunto de Prueba: (643, 4), (643,)\n"
     ]
    }
   ],
   "source": [
    "# Separación de datos con la función 'train_test_split'\n",
    "\n",
    "# Selección 'features' y 'target'\n",
    "\n",
    "features = data.drop('is_ultra', axis=1) # Seleccionamos las características de data pero eliminamos la característica 'is_ultra' que es el target del modelo\n",
    "target = data['is_ultra'] # Seleccionamos el target\n",
    "\n",
    "# Para tener los tres conjuntos del modelo que son, Train, Test y Valid vamos a utilizar 'train_test_split', así que haremos primero una separación de data en 'train' y en 'temp' posteriormente 'temp' lo dividiremos \n",
    "# para obtener 'test' y 'valid' \n",
    "\n",
    "features_train, features_temp, target_train, target_temp = train_test_split(features, target, test_size=0.4, random_state=42) # Tenemos listo el conjunto de entranamiento ahora segmentemos el temporal para obtener el de prueba y validación\n",
    "\n",
    "features_valid, features_prueba, target_valid, target_prueba = train_test_split(features_temp, target_temp, test_size=0.5, random_state=42) # Ahora tenemos los el conjunto de entranamiento, validación y prueba\n",
    "\n",
    "# features_train, target_train -> Conjunto de Entrenamiento\n",
    "# features_valid, target_valid -> Conjunto de Validación\n",
    "# features_prueba, target_prueba -> Conjunto de Prueba\n",
    "\n",
    "print(f'Conjunto de Entranamiento: {features_train.shape}, {target_train.shape}')\n",
    "print(f'Conjunto de Validación: {features_valid.shape}, {target_valid.shape}')\n",
    "print(f'Conjunto de Prueba: {features_prueba.shape}, {target_prueba.shape}')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Los datos segmentandos se utilizarán de la siguiente manera para optimizar al máximo el Modelo de Machine Learning\n",
    "\n",
    "* Conjunto de entrenamiento (60%): El modelo aprende patrones a partir de estos datos. Contiene el 60% del total de datos.\n",
    "\n",
    "* Conjunto de validación (20%): Se utiliza para ajustar los hiperparámetros y evaluar el modelo durante el desarrollo. Contiene el 20% del total de datos.\n",
    "\n",
    "* Conjunto de prueba (20%): Se utiliza solo al final para evaluar el rendimiento del modelo final. También contiene el 20% del total de datos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Etapa 3. Desarrollo del Modelo <a id='data_model'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1 - 3.2 Selección del Modelo y Entrenamiento del Modelo <a id='choose_model'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegresion - Precisión en Validación: 0.74\n",
      "RandomForestClassifier - Precisión en Validación: 0.81\n",
      "SVC - Precisión en Validación: 0.74\n"
     ]
    }
   ],
   "source": [
    "# Se realizarán las pruebas con tres modelos que son: `LogisticRegression`, `RandomForestClassifier`, `SVC`\n",
    "\n",
    "models = {\n",
    "    'LogisticRegresion': LogisticRegression(),\n",
    "    'RandomForestClassifier': RandomForestClassifier(),\n",
    "    'SVC': SVC()\n",
    "}\n",
    "\n",
    "for name_model, model in models.items():\n",
    "    model.fit(features_train, target_train)\n",
    "    model_predict = model.predict(features_valid)\n",
    "    accuracy = accuracy_score(target_valid, model_predict)\n",
    "    print(f'{name_model} - Precisión en Validación: {accuracy:.2f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.3 Ajuste de Hiperparámetros <a id=hyperparametres></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mejores Hiperparámetros:  {'max_depth': 10, 'n_estimators': 200}\n"
     ]
    }
   ],
   "source": [
    "# El mejor modelo que funciona es 'RandomForestClassifier' entonces ese utilizaremos junto con GridSearchCv que es una herramienta para encontrar la mejor combinación de modelos\n",
    "\n",
    "rf = RandomForestClassifier(random_state = 42)\n",
    "\n",
    "# Se define el espacio de búsqueda de Hiperparámetros\n",
    "\n",
    "param_grid = {\n",
    "    'n_estimators': [100, 200, 300],\n",
    "    'max_depth': [10, 20, 30]\n",
    "}\n",
    "\n",
    "# Configuram GridSearchCv\n",
    "grid_search = GridSearchCV(estimator= rf, param_grid = param_grid, cv = 3, scoring = 'accuracy')\n",
    "\n",
    "# Entrenamiento del Modelo con las combinaciones de los Hiperparámetros\n",
    "grid_search.fit(features_train, target_train)\n",
    "\n",
    "# Impresión de los mejores hiperparámetros\n",
    "print(f'Mejores Hiperparámetros: ', grid_search.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Optimizado - Precisión en Validación: 0.81\n"
     ]
    }
   ],
   "source": [
    "# Una vez que se vio cuáles son los mejores Hiperparámetros se pasará a escoger el mejor Modelo Entrenado\n",
    "best_model = grid_search.best_estimator_\n",
    "\n",
    "# Entrenar el modelo con los datos de prueba\n",
    "best_model_predict = best_model.predict(features_valid)\n",
    "\n",
    "# Calcular la precisión del Modelo de Prueba\n",
    "accuracy_prueba = accuracy_score(target_valid, best_model_predict)\n",
    "print(f'Random Forest Optimizado - Precisión en Validación: {accuracy_prueba:.2f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Etapa 4. Evaluación del Modelo <a id='model_evaluation'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.1 Prueba de Cordura <a id='cordura_prueba'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precisión del clasificador básico (most frequent): 0.70\n"
     ]
    }
   ],
   "source": [
    "# Mediante un modelo simple vamos a hacer la prueba de cordura este Modelo es DummyClassifier que predice la clase mas frecuenta y nos damos un idea de que tan bien nuestro modelo está aprendiendo de los datos de entrenamiento\n",
    "\n",
    "dummy_clf = DummyClassifier(strategy='most_frequent')\n",
    "\n",
    "# 2. Entrenar el DummyClassifier con los datos de entrenamiento\n",
    "dummy_clf.fit(features_train, target_train)\n",
    "\n",
    "# 3. Hacer predicciones en el conjunto de prueba\n",
    "dummy_pred = dummy_clf.predict(features_prueba)\n",
    "\n",
    "# 4. Calcular la precisión del DummyClassifier\n",
    "dummy_accuracy = accuracy_score(target_prueba, dummy_pred)\n",
    "print(f\"Precisión del clasificador básico (most frequent): {dummy_accuracy:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Después de hacer esta prueba de cordura vemos que el modelo de RandomForestClassifier esta funcionando, ya que su exactitud esta 11 puntos arriba que este cálculo básico que hizo DummyClassifier, lo cual nos dice que el modelo esta aprendiendo cosas útiles de los datos lo cual refleja que el modelo esta funcionando."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusiones finales del proyecto <a id='end'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Conclusión del Proyecto**\n",
    "\n",
    "En este proyecto, se desarrolló y evaluó un modelo de clasificación para la compañía móvil **Megaline** con el objetivo de recomendar a los clientes uno de sus planes nuevos: **Smart** o **Ultra**, basado en su comportamiento. A lo largo del proyecto, se siguió un enfoque estructurado para garantizar que el modelo construido fuera robusto, preciso y adecuado para la tarea.\n",
    "\n",
    "### **Resumen del proceso**:\n",
    "\n",
    "#### **Carga y exploración de los datos**:\n",
    "Se analizaron las variables disponibles en el conjunto de datos, que incluyen el número de llamadas, minutos totales, cantidad de mensajes de texto y uso de datos móviles (MB). La variable objetivo era el plan actual del usuario, que podía ser **Ultra** o **Smart**.\n",
    "\n",
    "#### **Preparación de los datos**:\n",
    "Los datos se dividieron en tres conjuntos: **entrenamiento**, **validación** y **prueba**. Esto permitió entrenar el modelo con el **80% de los datos** y reservar el **20% restante** para evaluar su rendimiento final.\n",
    "\n",
    "#### **Desarrollo del modelo**:\n",
    "Se probaron varios modelos de clasificación, como **Logistic Regression**, **Random Forest** y **Support Vector Machine (SVC)**. El mejor rendimiento lo ofreció **Random Forest**, con una precisión inicial de **0.81** en el conjunto de validación.\n",
    "\n",
    "#### **Ajuste de hiperparámetros**:\n",
    "Para mejorar el rendimiento, se ajustaron los hiperparámetros del modelo **Random Forest** utilizando **GridSearchCV**, lo que optimizó la combinación de parámetros. Tras la optimización, el modelo alcanzó una precisión de **0.82** en el conjunto de validación.\n",
    "\n",
    "#### **Evaluación del modelo**:\n",
    "Se utilizaron diversas métricas como **precisión**, **recall**, **F1-score** y **AUC-ROC** para evaluar el modelo en profundidad. Además, se realizó una **prueba de cordura** comparando el modelo optimizado con un **DummyClassifier**, el cual predice la clase más frecuente. El **DummyClassifier** obtuvo una precisión de **0.70**, mientras que el modelo optimizado alcanzó una precisión de **0.81**, demostrando que el modelo avanzado aprendió patrones útiles y no realizaba predicciones triviales.\n",
    "\n",
    "### **Resultados finales**:\n",
    "El modelo **Random Forest Optimizado** demostró ser altamente efectivo para la tarea, alcanzando una precisión final de **0.81** en el conjunto de prueba. Este modelo logró capturar patrones importantes del comportamiento de los clientes y es capaz de hacer recomendaciones precisas sobre qué plan deberían elegir. Esto resulta útil para **Megaline** en su estrategia para migrar clientes a planes más adecuados.\n",
    "\n",
    "### **Conclusión general**:\n",
    "El proyecto cumplió su objetivo principal: construir un modelo que pudiera analizar el comportamiento de los clientes y recomendar uno de los nuevos planes de **Megaline** con alta precisión. El rendimiento obtenido, con una precisión de **0.81**, supera la línea base del **DummyClassifier** y demuestra que el modelo está aprendiendo de manera significativa. Esto proporciona una herramienta confiable para que **Megaline** optimice sus decisiones comerciales y ofrezca mejores servicios a sus clientes.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
